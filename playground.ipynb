{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'src')\n",
    "\n",
    "from network import BF_CNN\n",
    "from universal_inverse_solve import universal_inverse_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 28, 28]          576\n",
      "|    └─Conv2d: 2-2                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-4                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-6                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-8                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-9                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-10                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-11                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-12                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-13                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-14                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-15                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-16                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-17                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-18                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-19                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-20                      [-1, 1, 28, 28]           576\n",
      "==========================================================================================\n",
      "Total params: 664,704\n",
      "Trainable params: 664,704\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 521.13\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.28\n",
      "Params size (MB): 2.54\n",
      "Estimated Total Size (MB): 9.82\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 28, 28]          576\n",
       "|    └─Conv2d: 2-2                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-4                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-6                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-7                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-8                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-9                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-10                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-11                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-12                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-13                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-14                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-15                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-16                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-17                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-18                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-19                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-20                      [-1, 1, 28, 28]           576\n",
       "==========================================================================================\n",
       "Total params: 664,704\n",
       "Trainable params: 664,704\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 521.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 7.28\n",
       "Params size (MB): 2.54\n",
       "Estimated Total Size (MB): 9.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the denoiser architecture\n",
    "denoiser = BF_CNN()\n",
    "\n",
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    denoiser = denoiser.cuda()\n",
    "\n",
    "# Load the learned parameters\n",
    "denoiser_path = os.path.join('denoisers','mnist.pt')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    learned_params =torch.load(denoiser_path)\n",
    "else:\n",
    "    learned_params =torch.load(denoiser_path, map_location='cpu')\n",
    "\n",
    "denoiser.load_state_dict(learned_params)\n",
    "\n",
    "# Show summary of the denoiser\n",
    "summary(denoiser, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "matmul(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/michaelbryant/Library/Mobile Documents/com~apple~CloudDocs/Duke/Junior/ECE588/universal_inverse_implementation/playground.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelbryant/Library/Mobile%20Documents/com~apple~CloudDocs/Duke/Junior/ECE588/universal_inverse_implementation/playground.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m patch_size \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m, \u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m) \u001b[39m# 1 channel, 28x28\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/michaelbryant/Library/Mobile%20Documents/com~apple~CloudDocs/Duke/Junior/ECE588/universal_inverse_implementation/playground.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m x_c \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(patch_size) \n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/michaelbryant/Library/Mobile%20Documents/com~apple~CloudDocs/Duke/Junior/ECE588/universal_inverse_implementation/playground.ipynb#X41sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m synth \u001b[39m=\u001b[39m universal_inverse_solver(M, M_T, x_c, denoiser)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Duke/Junior/ECE588/universal_inverse_implementation/src/universal_inverse_solve.py:15\u001b[0m, in \u001b[0;36muniversal_inverse_solver\u001b[0;34m(M, M_T, x_c, denoiser, sigma_0, sigma_L, h_0, beta)\u001b[0m\n\u001b[1;32m     12\u001b[0m e \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(x_c\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Draw y_0 from N(0.5 * (I - M^T M) e + M * x_c , sigma_0^2 * I)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m y_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdistributions\u001b[39m.\u001b[39mnormal\u001b[39m.\u001b[39mNormal(\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (torch\u001b[39m.\u001b[39meye(x_c\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(M_T, M)) \u001b[39m*\u001b[39m e \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mmatmul(M, x_c), sigma_0 \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39meye(x_c\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39msample()\n\u001b[1;32m     17\u001b[0m sigma_t \u001b[39m=\u001b[39m sigma_0\n\u001b[1;32m     19\u001b[0m \u001b[39mwhile\u001b[39;00m sigma_t \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m sigma_L:\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m     \u001b[39m# Step size\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: matmul(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# def universal_inverse_solver(M, M_T, x_c, denoiser, sigma_0=1, sigma_L=0.01, h_0=0.01, beta=0.01):\n",
    "\n",
    "\n",
    "# For synthesis, both M and M_T are zero like or shape sample image\n",
    "# Images are mnist, so 28x28\n",
    "M = np.zeros_like(28)\n",
    "M_T = np.zeros_like(28)\n",
    "\n",
    "# Input image is 28x28 of zeros and noise will be added to it\n",
    "# This will be synthesized by the denoiser\n",
    "\n",
    "patch_size = (1, 28, 28) # 1 channel, 28x28\n",
    "x_c = torch.zeros(patch_size) \n",
    "\n",
    "\n",
    "synth = universal_inverse_solver(M, M_T, x_c, denoiser)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
