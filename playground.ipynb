{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'src')\n",
    "\n",
    "from network import BF_CNN\n",
    "# from universal_inverse_solve import universal_inverse_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 28, 28]          576\n",
      "|    └─Conv2d: 2-2                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-4                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-6                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-8                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-9                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-10                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-11                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-12                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-13                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-14                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-15                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-16                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-17                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-18                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-19                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-20                      [-1, 1, 28, 28]           576\n",
      "==========================================================================================\n",
      "Total params: 664,704\n",
      "Trainable params: 664,704\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 521.13\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.28\n",
      "Params size (MB): 2.54\n",
      "Estimated Total Size (MB): 9.82\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 28, 28]          576\n",
       "|    └─Conv2d: 2-2                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-4                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-6                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-7                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-8                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-9                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-10                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-11                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-12                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-13                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-14                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-15                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-16                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-17                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-18                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-19                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-20                      [-1, 1, 28, 28]           576\n",
       "==========================================================================================\n",
       "Total params: 664,704\n",
       "Trainable params: 664,704\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 521.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 7.28\n",
       "Params size (MB): 2.54\n",
       "Estimated Total Size (MB): 9.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the denoiser architecture\n",
    "denoiser = BF_CNN()\n",
    "\n",
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    denoiser = denoiser.cuda()\n",
    "\n",
    "# Load the learned parameters\n",
    "denoiser_path = os.path.join('denoisers','mnist.pt')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    learned_params = torch.load(denoiser_path)\n",
    "else:\n",
    "    learned_params = torch.load(denoiser_path, map_location='cpu')\n",
    "\n",
    "denoiser.load_state_dict(learned_params)\n",
    "\n",
    "denoiser.eval()\n",
    "\n",
    "# Show summary of the denoiser\n",
    "summary(denoiser, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def universal_inverse_solver(x_c, denoiser, sigma_0=1, sigma_L=0.01, h_0=0.01, beta=0.01):\n",
    "\n",
    "    # M and M_T depend on the task we are performing, so input them as arguments depending on the task (ex infill)\n",
    "\n",
    "    t = 1\n",
    "\n",
    "    # For synthesis for now, M and M_T are just 0\n",
    "    M = lambda x: torch.zeros_like(x)\n",
    "    M_T = lambda x: torch.zeros_like(x)\n",
    "\n",
    "    # N is the number of pixels in the image\n",
    "    N = x_c.shape[2] * x_c.shape[1]\n",
    "\n",
    "    # e is a matrix of 1's the shape of x_c\n",
    "    e = torch.ones_like(M(x_c), requires_grad= False)\n",
    "\n",
    "    # Draw y_0 from N(0.5 * (I - M^T M) e + M * x_c , sigma_0^2 * I)\n",
    "    # y_t = torch.normal(0.5 * (torch.eye(x_c.shape[0]) - M_T(M(e))) + M(x_c), sigma_0 ** 2 * torch.eye(x_c.shape[0]))\n",
    "    y_t = torch.normal((e - M(M_T(e)))/2 + M(x_c), sigma_0)\n",
    "    y_t = y_t.unsqueeze(0)\n",
    "    y_t.requires_grad = False\n",
    "\n",
    "    f = denoiser(y_t)\n",
    "    sigma = torch.norm(f)/np.sqrt(N)\n",
    "\n",
    "    print(sigma, sigma_L)\n",
    "    print(sigma >sigma_L)\n",
    "\n",
    "    # max_count = 100\n",
    "\n",
    "    while sigma > sigma_L:\n",
    "\n",
    "        print(f'Sigma: {sigma}, t: {t}, Sigma_L {sigma_L}')\n",
    "\n",
    "        # Step size\n",
    "        h_t = h_0 * t / (1 + h_0 * (t - 1))\n",
    "\n",
    "        # Denoised image\n",
    "        #  f(y_t) = x^ (y) - y\n",
    "        # Denoised is the output of the denoiser - the original image\n",
    "        f = denoiser(y_t)\n",
    "\n",
    "        # d_t = (I - M M^T) f(y_t) + M (x_c - M^T y_t) \n",
    "        d_t = f - M(M_T(f[0])) + M(M_T(y_t[0])) - M(x_c)\n",
    "\n",
    "        # sigma_t = sqrt(abs(d_t)^2/N)\n",
    "\n",
    "        sigma = torch.norm(d_t)/np.sqrt(N)\n",
    "\n",
    "        # gamma_t = sqrt((1 beta * h_t)^2 - (1 - h_t)^2) * sigma_t^2)\n",
    "        gamma_t = np.sqrt((1 - beta * h_t) ** 2 - (1 - h_t) ** 2) * sigma\n",
    "\n",
    "        # Draw z_t from N(0, I)\n",
    "        # z_t = torch.normal(0, 1)\n",
    "        z_t = torch.randn(1, x_c.shape[2], x_c.shape[1])\n",
    "\n",
    "        y_t = y_t - h_t * d_t + gamma_t * z_t\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return y_t - denoiser(y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9695, grad_fn=<DivBackward0>) 0.01\n",
      "tensor(True)\n",
      "Sigma: 0.969451367855072, t: 1, Sigma_L 0.01\n",
      "Sigma: 0.969451367855072, t: 2, Sigma_L 0.01\n",
      "Sigma: 0.9721242189407349, t: 3, Sigma_L 0.01\n",
      "Sigma: 0.9748350381851196, t: 4, Sigma_L 0.01\n",
      "Sigma: 0.9862044453620911, t: 5, Sigma_L 0.01\n",
      "Sigma: 0.9913339614868164, t: 6, Sigma_L 0.01\n",
      "Sigma: 0.9848958849906921, t: 7, Sigma_L 0.01\n",
      "Sigma: 0.982536256313324, t: 8, Sigma_L 0.01\n",
      "Sigma: 0.9748967885971069, t: 9, Sigma_L 0.01\n",
      "Sigma: 0.9957767128944397, t: 10, Sigma_L 0.01\n",
      "Sigma: 1.003604531288147, t: 11, Sigma_L 0.01\n",
      "Sigma: 1.0099624395370483, t: 12, Sigma_L 0.01\n",
      "Sigma: 1.013098955154419, t: 13, Sigma_L 0.01\n",
      "Sigma: 1.0206472873687744, t: 14, Sigma_L 0.01\n",
      "Sigma: 1.0331599712371826, t: 15, Sigma_L 0.01\n",
      "Sigma: 1.0533653497695923, t: 16, Sigma_L 0.01\n",
      "Sigma: 1.051714539527893, t: 17, Sigma_L 0.01\n",
      "Sigma: 1.0361632108688354, t: 18, Sigma_L 0.01\n",
      "Sigma: 1.0253268480300903, t: 19, Sigma_L 0.01\n",
      "Sigma: 1.0064043998718262, t: 20, Sigma_L 0.01\n",
      "Sigma: 1.012909173965454, t: 21, Sigma_L 0.01\n",
      "Sigma: 0.9858837723731995, t: 22, Sigma_L 0.01\n",
      "Sigma: 1.0045305490493774, t: 23, Sigma_L 0.01\n",
      "Sigma: 1.009329915046692, t: 24, Sigma_L 0.01\n",
      "Sigma: 0.9839216470718384, t: 25, Sigma_L 0.01\n",
      "Sigma: 0.9792513251304626, t: 26, Sigma_L 0.01\n",
      "Sigma: 1.0012824535369873, t: 27, Sigma_L 0.01\n",
      "Sigma: 0.9790975451469421, t: 28, Sigma_L 0.01\n",
      "Sigma: 0.9329754710197449, t: 29, Sigma_L 0.01\n",
      "Sigma: 0.9445737600326538, t: 30, Sigma_L 0.01\n",
      "Sigma: 0.9152387976646423, t: 31, Sigma_L 0.01\n",
      "Sigma: 0.8950956463813782, t: 32, Sigma_L 0.01\n",
      "Sigma: 0.8761319518089294, t: 33, Sigma_L 0.01\n",
      "Sigma: 0.8979188203811646, t: 34, Sigma_L 0.01\n",
      "Sigma: 0.9042072296142578, t: 35, Sigma_L 0.01\n",
      "Sigma: 0.917279839515686, t: 36, Sigma_L 0.01\n",
      "Sigma: 0.9331148266792297, t: 37, Sigma_L 0.01\n",
      "Sigma: 0.9135792851448059, t: 38, Sigma_L 0.01\n",
      "Sigma: 0.9029805064201355, t: 39, Sigma_L 0.01\n",
      "Sigma: 0.9208114743232727, t: 40, Sigma_L 0.01\n",
      "Sigma: 0.9147120118141174, t: 41, Sigma_L 0.01\n",
      "Sigma: 0.9170011878013611, t: 42, Sigma_L 0.01\n",
      "Sigma: 0.8961997032165527, t: 43, Sigma_L 0.01\n",
      "Sigma: 0.9043313264846802, t: 44, Sigma_L 0.01\n",
      "Sigma: 0.9121613502502441, t: 45, Sigma_L 0.01\n",
      "Sigma: 0.902067244052887, t: 46, Sigma_L 0.01\n",
      "Sigma: 0.9360893368721008, t: 47, Sigma_L 0.01\n",
      "Sigma: 0.9171260595321655, t: 48, Sigma_L 0.01\n",
      "Sigma: 0.8870730400085449, t: 49, Sigma_L 0.01\n",
      "Sigma: 0.8679302334785461, t: 50, Sigma_L 0.01\n",
      "Sigma: 0.8327668309211731, t: 51, Sigma_L 0.01\n",
      "Sigma: 0.8274465799331665, t: 52, Sigma_L 0.01\n",
      "Sigma: 0.8215765357017517, t: 53, Sigma_L 0.01\n",
      "Sigma: 0.8118723034858704, t: 54, Sigma_L 0.01\n",
      "Sigma: 0.7637256979942322, t: 55, Sigma_L 0.01\n",
      "Sigma: 0.7735235095024109, t: 56, Sigma_L 0.01\n",
      "Sigma: 0.7809853553771973, t: 57, Sigma_L 0.01\n",
      "Sigma: 0.7817811369895935, t: 58, Sigma_L 0.01\n",
      "Sigma: 0.7889341711997986, t: 59, Sigma_L 0.01\n",
      "Sigma: 0.7921142578125, t: 60, Sigma_L 0.01\n",
      "Sigma: 0.7825254797935486, t: 61, Sigma_L 0.01\n",
      "Sigma: 0.72881019115448, t: 62, Sigma_L 0.01\n",
      "Sigma: 0.724955677986145, t: 63, Sigma_L 0.01\n",
      "Sigma: 0.6949256658554077, t: 64, Sigma_L 0.01\n",
      "Sigma: 0.6648938059806824, t: 65, Sigma_L 0.01\n",
      "Sigma: 0.6555854678153992, t: 66, Sigma_L 0.01\n",
      "Sigma: 0.6495401263237, t: 67, Sigma_L 0.01\n",
      "Sigma: 0.6379575133323669, t: 68, Sigma_L 0.01\n",
      "Sigma: 0.6154559850692749, t: 69, Sigma_L 0.01\n",
      "Sigma: 0.6033567786216736, t: 70, Sigma_L 0.01\n",
      "Sigma: 0.5872729420661926, t: 71, Sigma_L 0.01\n",
      "Sigma: 0.5756891965866089, t: 72, Sigma_L 0.01\n",
      "Sigma: 0.5838509202003479, t: 73, Sigma_L 0.01\n",
      "Sigma: 0.5861111283302307, t: 74, Sigma_L 0.01\n",
      "Sigma: 0.5947393774986267, t: 75, Sigma_L 0.01\n",
      "Sigma: 0.5883903503417969, t: 76, Sigma_L 0.01\n",
      "Sigma: 0.5806720852851868, t: 77, Sigma_L 0.01\n",
      "Sigma: 0.5551996827125549, t: 78, Sigma_L 0.01\n",
      "Sigma: 0.5409820079803467, t: 79, Sigma_L 0.01\n",
      "Sigma: 0.5147334337234497, t: 80, Sigma_L 0.01\n",
      "Sigma: 0.4912453293800354, t: 81, Sigma_L 0.01\n",
      "Sigma: 0.47885093092918396, t: 82, Sigma_L 0.01\n",
      "Sigma: 0.4584534466266632, t: 83, Sigma_L 0.01\n",
      "Sigma: 0.45304301381111145, t: 84, Sigma_L 0.01\n",
      "Sigma: 0.4528833329677582, t: 85, Sigma_L 0.01\n",
      "Sigma: 0.43785762786865234, t: 86, Sigma_L 0.01\n",
      "Sigma: 0.4166361689567566, t: 87, Sigma_L 0.01\n",
      "Sigma: 0.40427109599113464, t: 88, Sigma_L 0.01\n",
      "Sigma: 0.403233140707016, t: 89, Sigma_L 0.01\n",
      "Sigma: 0.40776076912879944, t: 90, Sigma_L 0.01\n",
      "Sigma: 0.4128386378288269, t: 91, Sigma_L 0.01\n",
      "Sigma: 0.40231218934059143, t: 92, Sigma_L 0.01\n",
      "Sigma: 0.38510724902153015, t: 93, Sigma_L 0.01\n",
      "Sigma: 0.3976256549358368, t: 94, Sigma_L 0.01\n",
      "Sigma: 0.3930024802684784, t: 95, Sigma_L 0.01\n",
      "Sigma: 0.37278619408607483, t: 96, Sigma_L 0.01\n",
      "Sigma: 0.37896034121513367, t: 97, Sigma_L 0.01\n",
      "Sigma: 0.37756064534187317, t: 98, Sigma_L 0.01\n",
      "Sigma: 0.38744527101516724, t: 99, Sigma_L 0.01\n",
      "Sigma: 0.38776060938835144, t: 100, Sigma_L 0.01\n",
      "Sigma: 0.375489741563797, t: 101, Sigma_L 0.01\n",
      "Sigma: 0.3643180727958679, t: 102, Sigma_L 0.01\n",
      "Sigma: 0.34949252009391785, t: 103, Sigma_L 0.01\n",
      "Sigma: 0.34033989906311035, t: 104, Sigma_L 0.01\n",
      "Sigma: 0.3200511932373047, t: 105, Sigma_L 0.01\n",
      "Sigma: 0.3155699372291565, t: 106, Sigma_L 0.01\n",
      "Sigma: 0.3016190528869629, t: 107, Sigma_L 0.01\n",
      "Sigma: 0.2969290316104889, t: 108, Sigma_L 0.01\n",
      "Sigma: 0.30258551239967346, t: 109, Sigma_L 0.01\n",
      "Sigma: 0.30187085270881653, t: 110, Sigma_L 0.01\n",
      "Sigma: 0.2956917881965637, t: 111, Sigma_L 0.01\n",
      "Sigma: 0.29495948553085327, t: 112, Sigma_L 0.01\n",
      "Sigma: 0.29681724309921265, t: 113, Sigma_L 0.01\n",
      "Sigma: 0.2856360077857971, t: 114, Sigma_L 0.01\n",
      "Sigma: 0.2796151638031006, t: 115, Sigma_L 0.01\n",
      "Sigma: 0.27751854062080383, t: 116, Sigma_L 0.01\n",
      "Sigma: 0.2642630636692047, t: 117, Sigma_L 0.01\n",
      "Sigma: 0.2578992247581482, t: 118, Sigma_L 0.01\n",
      "Sigma: 0.26300790905952454, t: 119, Sigma_L 0.01\n",
      "Sigma: 0.2536012828350067, t: 120, Sigma_L 0.01\n",
      "Sigma: 0.23738929629325867, t: 121, Sigma_L 0.01\n",
      "Sigma: 0.22026272118091583, t: 122, Sigma_L 0.01\n",
      "Sigma: 0.21431134641170502, t: 123, Sigma_L 0.01\n",
      "Sigma: 0.21336190402507782, t: 124, Sigma_L 0.01\n",
      "Sigma: 0.21549727022647858, t: 125, Sigma_L 0.01\n",
      "Sigma: 0.20644862949848175, t: 126, Sigma_L 0.01\n",
      "Sigma: 0.2012936919927597, t: 127, Sigma_L 0.01\n",
      "Sigma: 0.18499855697155, t: 128, Sigma_L 0.01\n",
      "Sigma: 0.18158598244190216, t: 129, Sigma_L 0.01\n",
      "Sigma: 0.17702247202396393, t: 130, Sigma_L 0.01\n",
      "Sigma: 0.17580783367156982, t: 131, Sigma_L 0.01\n",
      "Sigma: 0.16858987510204315, t: 132, Sigma_L 0.01\n",
      "Sigma: 0.1611311435699463, t: 133, Sigma_L 0.01\n",
      "Sigma: 0.15238995850086212, t: 134, Sigma_L 0.01\n",
      "Sigma: 0.14928866922855377, t: 135, Sigma_L 0.01\n",
      "Sigma: 0.14546997845172882, t: 136, Sigma_L 0.01\n",
      "Sigma: 0.1439269334077835, t: 137, Sigma_L 0.01\n",
      "Sigma: 0.14038731157779694, t: 138, Sigma_L 0.01\n",
      "Sigma: 0.13886450231075287, t: 139, Sigma_L 0.01\n",
      "Sigma: 0.1362515538930893, t: 140, Sigma_L 0.01\n",
      "Sigma: 0.13215626776218414, t: 141, Sigma_L 0.01\n",
      "Sigma: 0.13335992395877838, t: 142, Sigma_L 0.01\n",
      "Sigma: 0.12513995170593262, t: 143, Sigma_L 0.01\n",
      "Sigma: 0.12213976681232452, t: 144, Sigma_L 0.01\n",
      "Sigma: 0.11934556066989899, t: 145, Sigma_L 0.01\n",
      "Sigma: 0.11382580548524857, t: 146, Sigma_L 0.01\n",
      "Sigma: 0.11047763377428055, t: 147, Sigma_L 0.01\n",
      "Sigma: 0.1024533286690712, t: 148, Sigma_L 0.01\n",
      "Sigma: 0.10420294851064682, t: 149, Sigma_L 0.01\n",
      "Sigma: 0.1029290035367012, t: 150, Sigma_L 0.01\n",
      "Sigma: 0.09561271220445633, t: 151, Sigma_L 0.01\n",
      "Sigma: 0.09519469738006592, t: 152, Sigma_L 0.01\n",
      "Sigma: 0.09255104511976242, t: 153, Sigma_L 0.01\n",
      "Sigma: 0.09721444547176361, t: 154, Sigma_L 0.01\n",
      "Sigma: 0.09671138972043991, t: 155, Sigma_L 0.01\n",
      "Sigma: 0.09326647222042084, t: 156, Sigma_L 0.01\n",
      "Sigma: 0.0944327786564827, t: 157, Sigma_L 0.01\n",
      "Sigma: 0.09030356258153915, t: 158, Sigma_L 0.01\n",
      "Sigma: 0.08948635309934616, t: 159, Sigma_L 0.01\n",
      "Sigma: 0.0836033746600151, t: 160, Sigma_L 0.01\n",
      "Sigma: 0.07822204381227493, t: 161, Sigma_L 0.01\n",
      "Sigma: 0.07457542419433594, t: 162, Sigma_L 0.01\n",
      "Sigma: 0.07150392979383469, t: 163, Sigma_L 0.01\n",
      "Sigma: 0.07013215869665146, t: 164, Sigma_L 0.01\n",
      "Sigma: 0.06815312802791595, t: 165, Sigma_L 0.01\n",
      "Sigma: 0.0697781965136528, t: 166, Sigma_L 0.01\n",
      "Sigma: 0.06720685958862305, t: 167, Sigma_L 0.01\n",
      "Sigma: 0.06496470421552658, t: 168, Sigma_L 0.01\n",
      "Sigma: 0.06466352194547653, t: 169, Sigma_L 0.01\n",
      "Sigma: 0.06444457918405533, t: 170, Sigma_L 0.01\n",
      "Sigma: 0.06158239021897316, t: 171, Sigma_L 0.01\n",
      "Sigma: 0.06141713634133339, t: 172, Sigma_L 0.01\n",
      "Sigma: 0.061230503022670746, t: 173, Sigma_L 0.01\n",
      "Sigma: 0.05928609147667885, t: 174, Sigma_L 0.01\n",
      "Sigma: 0.057351283729076385, t: 175, Sigma_L 0.01\n",
      "Sigma: 0.056492771953344345, t: 176, Sigma_L 0.01\n",
      "Sigma: 0.05764878913760185, t: 177, Sigma_L 0.01\n",
      "Sigma: 0.05616516247391701, t: 178, Sigma_L 0.01\n",
      "Sigma: 0.05522849038243294, t: 179, Sigma_L 0.01\n",
      "Sigma: 0.052114687860012054, t: 180, Sigma_L 0.01\n",
      "Sigma: 0.051239870488643646, t: 181, Sigma_L 0.01\n",
      "Sigma: 0.050234317779541016, t: 182, Sigma_L 0.01\n",
      "Sigma: 0.047511689364910126, t: 183, Sigma_L 0.01\n",
      "Sigma: 0.04738346487283707, t: 184, Sigma_L 0.01\n",
      "Sigma: 0.044762905687093735, t: 185, Sigma_L 0.01\n",
      "Sigma: 0.04352717474102974, t: 186, Sigma_L 0.01\n",
      "Sigma: 0.04306669160723686, t: 187, Sigma_L 0.01\n",
      "Sigma: 0.041757941246032715, t: 188, Sigma_L 0.01\n",
      "Sigma: 0.040630191564559937, t: 189, Sigma_L 0.01\n",
      "Sigma: 0.03663359209895134, t: 190, Sigma_L 0.01\n",
      "Sigma: 0.03575585037469864, t: 191, Sigma_L 0.01\n",
      "Sigma: 0.03371378406882286, t: 192, Sigma_L 0.01\n",
      "Sigma: 0.03159249201416969, t: 193, Sigma_L 0.01\n",
      "Sigma: 0.029914874583482742, t: 194, Sigma_L 0.01\n",
      "Sigma: 0.028923513367772102, t: 195, Sigma_L 0.01\n",
      "Sigma: 0.028387589380145073, t: 196, Sigma_L 0.01\n",
      "Sigma: 0.028269637376070023, t: 197, Sigma_L 0.01\n",
      "Sigma: 0.02750016376376152, t: 198, Sigma_L 0.01\n",
      "Sigma: 0.02614135667681694, t: 199, Sigma_L 0.01\n",
      "Sigma: 0.02455533668398857, t: 200, Sigma_L 0.01\n",
      "Sigma: 0.022824134677648544, t: 201, Sigma_L 0.01\n",
      "Sigma: 0.02218015305697918, t: 202, Sigma_L 0.01\n",
      "Sigma: 0.021993523463606834, t: 203, Sigma_L 0.01\n",
      "Sigma: 0.02195730432868004, t: 204, Sigma_L 0.01\n",
      "Sigma: 0.02081732451915741, t: 205, Sigma_L 0.01\n",
      "Sigma: 0.020759299397468567, t: 206, Sigma_L 0.01\n",
      "Sigma: 0.020395228639245033, t: 207, Sigma_L 0.01\n",
      "Sigma: 0.020719528198242188, t: 208, Sigma_L 0.01\n",
      "Sigma: 0.01960526779294014, t: 209, Sigma_L 0.01\n",
      "Sigma: 0.018567966297268867, t: 210, Sigma_L 0.01\n",
      "Sigma: 0.01765560917556286, t: 211, Sigma_L 0.01\n",
      "Sigma: 0.016511861234903336, t: 212, Sigma_L 0.01\n",
      "Sigma: 0.015662016347050667, t: 213, Sigma_L 0.01\n",
      "Sigma: 0.015292526222765446, t: 214, Sigma_L 0.01\n",
      "Sigma: 0.014669905416667461, t: 215, Sigma_L 0.01\n",
      "Sigma: 0.01417260617017746, t: 216, Sigma_L 0.01\n",
      "Sigma: 0.013387380167841911, t: 217, Sigma_L 0.01\n",
      "Sigma: 0.013088410720229149, t: 218, Sigma_L 0.01\n",
      "Sigma: 0.011912492103874683, t: 219, Sigma_L 0.01\n",
      "Sigma: 0.010955138131976128, t: 220, Sigma_L 0.01\n",
      "Sigma: 0.010159921832382679, t: 221, Sigma_L 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For synthesis, both M and M_T are zero like or shape sample image\n",
    "# Images are mnist, so 28x28\n",
    "# Create a Tensor of zeros with the same shape as the sample image\n",
    "\n",
    "# Input image is 28x28 of zeros and noise will be added to it\n",
    "# This will be synthesized by the denoiser\n",
    "patch_size = (1, 28, 28) # 1 channel, 28x28\n",
    "x_c = torch.zeros(patch_size) \n",
    "\n",
    "synth = universal_inverse_solver(x_c, denoiser)\n",
    "\n",
    "# Reshape the synthesized image to be 28x28\n",
    "synth = synth.view(1,1,28,28)\n",
    "\n",
    "# Show synthesized image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(synth[0,0,:,:].detach().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
