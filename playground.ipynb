{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, 'src')\n",
    "\n",
    "from network import BF_CNN\n",
    "# from universal_inverse_solve import universal_inverse_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─ModuleList: 1                          []                        --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 28, 28]          576\n",
      "|    └─Conv2d: 2-2                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-4                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-5                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-6                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-8                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-9                       [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-10                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-11                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-12                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-13                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-14                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-15                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-16                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-17                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-18                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-19                      [-1, 64, 28, 28]          36,864\n",
      "|    └─Conv2d: 2-20                      [-1, 1, 28, 28]           576\n",
      "==========================================================================================\n",
      "Total params: 664,704\n",
      "Trainable params: 664,704\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 521.13\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.28\n",
      "Params size (MB): 2.54\n",
      "Estimated Total Size (MB): 9.82\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─ModuleList: 1                          []                        --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 28, 28]          576\n",
       "|    └─Conv2d: 2-2                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-3                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-4                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-5                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-6                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-7                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-8                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-9                       [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-10                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-11                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-12                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-13                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-14                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-15                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-16                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-17                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-18                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-19                      [-1, 64, 28, 28]          36,864\n",
       "|    └─Conv2d: 2-20                      [-1, 1, 28, 28]           576\n",
       "==========================================================================================\n",
       "Total params: 664,704\n",
       "Trainable params: 664,704\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 521.13\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 7.28\n",
       "Params size (MB): 2.54\n",
       "Estimated Total Size (MB): 9.82\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the denoiser architecture\n",
    "denoiser = BF_CNN()\n",
    "\n",
    "# Use GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    denoiser = denoiser.cuda()\n",
    "\n",
    "# Load the learned parameters\n",
    "denoiser_path = os.path.join('denoisers','mnist.pt')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    learned_params =torch.load(denoiser_path)\n",
    "else:\n",
    "    learned_params =torch.load(denoiser_path, map_location='cpu')\n",
    "\n",
    "denoiser.load_state_dict(learned_params)\n",
    "\n",
    "# Show summary of the denoiser\n",
    "summary(denoiser, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def universal_inverse_solver(x_c, denoiser, sigma_0=1, sigma_L=0.01, h_0=0.01, beta=0.01):\n",
    "\n",
    "    # M and M_T depend on the task we are performing, so input them as arguments depending on the task (ex infill)\n",
    "\n",
    "    t = 1\n",
    "\n",
    "    # For synthesis for now, M and M_T are just 0\n",
    "    M = lambda x: torch.zeros_like(x)\n",
    "    M_T = lambda x: torch.zeros_like(x)\n",
    "\n",
    "    # N is the number of pixels in the image\n",
    "    N = x_c.shape[2] * x_c.shape[1]\n",
    "\n",
    "    # e is a matrix of 1's the shape of x_c\n",
    "    e = torch.ones_like(M(x_c), requires_grad= False)\n",
    "\n",
    "    # Draw y_0 from N(0.5 * (I - M^T M) e + M * x_c , sigma_0^2 * I)\n",
    "    # y_t = torch.normal(0.5 * (torch.eye(x_c.shape[0]) - M_T(M(e))) + M(x_c), sigma_0 ** 2 * torch.eye(x_c.shape[0]))\n",
    "    y_t = torch.normal((e - M(M_T(e)))*.5 + M(x_c), sigma_0)\n",
    "    y_t = y_t.unsqueeze(0)\n",
    "    y_t.requires_grad = False\n",
    "\n",
    "    f = denoiser(y_t)\n",
    "    sigma = torch.norm(f)/np.sqrt(N)\n",
    "\n",
    "    print(sigma, sigma_L)\n",
    "    print(sigma >sigma_L)\n",
    "\n",
    "    # max_count = 100\n",
    "\n",
    "    while sigma > sigma_L:\n",
    "\n",
    "        print(f'Sigma: {sigma}, t: {t}, Sigma_L {sigma_L}')\n",
    "\n",
    "        # Step size\n",
    "        h_t = (h_0 * t) / (1 + h_0 * (t - 1))\n",
    "\n",
    "        # Denoised image\n",
    "        #  f(y_t) = x^ (y) - y\n",
    "        # Denoised is the output of the denoiser - the original image\n",
    "        f = denoiser(y_t)\n",
    "\n",
    "        # d_t = (I - M M^T) f(y_t) + M (x_c - M^T y_t) \n",
    "        d_t = f - M(M_T(f[0])) + M(M_T(y_t[0])) - M(x_c)\n",
    "\n",
    "        # sigma_t = sqrt(abs(d_t)^2/N)\n",
    "\n",
    "        sigma = torch.norm(d_t)/np.sqrt(N)\n",
    "\n",
    "        # gamma_t = sqrt((1 beta * h_t)^2 - (1 - h_t)^2) * sigma_t^2)\n",
    "        gamma_t = np.sqrt((1 - beta * h_t) ** 2 - (1 - h_t) ** 2) * sigma\n",
    "\n",
    "        # Draw z_t from N(0, I)\n",
    "        # z_t = torch.normal(0, 1)\n",
    "        z_t = torch.randn(1, x_c.shape[2], x_c.shape[1])\n",
    "\n",
    "        y_t = y_t - h_t * d_t + gamma_t * z_t\n",
    "\n",
    "        t += 1\n",
    "\n",
    "    return y_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2706, grad_fn=<DivBackward0>) 0.01\n",
      "tensor(True)\n",
      "Sigma: 0.2705945372581482, t: 1, Sigma_L 0.01\n",
      "Sigma: 0.2705945372581482, t: 2, Sigma_L 0.01\n",
      "Sigma: 0.27071282267570496, t: 3, Sigma_L 0.01\n",
      "Sigma: 0.27134469151496887, t: 4, Sigma_L 0.01\n",
      "Sigma: 0.27129068970680237, t: 5, Sigma_L 0.01\n",
      "Sigma: 0.2706737220287323, t: 6, Sigma_L 0.01\n",
      "Sigma: 0.27192726731300354, t: 7, Sigma_L 0.01\n",
      "Sigma: 0.2726801931858063, t: 8, Sigma_L 0.01\n",
      "Sigma: 0.27333635091781616, t: 9, Sigma_L 0.01\n",
      "Sigma: 0.2728712856769562, t: 10, Sigma_L 0.01\n",
      "Sigma: 0.27445298433303833, t: 11, Sigma_L 0.01\n",
      "Sigma: 0.27388301491737366, t: 12, Sigma_L 0.01\n",
      "Sigma: 0.274140864610672, t: 13, Sigma_L 0.01\n",
      "Sigma: 0.2748594880104065, t: 14, Sigma_L 0.01\n",
      "Sigma: 0.2733781933784485, t: 15, Sigma_L 0.01\n",
      "Sigma: 0.2722248435020447, t: 16, Sigma_L 0.01\n",
      "Sigma: 0.2724495828151703, t: 17, Sigma_L 0.01\n",
      "Sigma: 0.27463826537132263, t: 18, Sigma_L 0.01\n",
      "Sigma: 0.2762077748775482, t: 19, Sigma_L 0.01\n",
      "Sigma: 0.2755678594112396, t: 20, Sigma_L 0.01\n",
      "Sigma: 0.2735455334186554, t: 21, Sigma_L 0.01\n",
      "Sigma: 0.2753542363643646, t: 22, Sigma_L 0.01\n",
      "Sigma: 0.27692171931266785, t: 23, Sigma_L 0.01\n",
      "Sigma: 0.2776588499546051, t: 24, Sigma_L 0.01\n",
      "Sigma: 0.2770865857601166, t: 25, Sigma_L 0.01\n",
      "Sigma: 0.27745988965034485, t: 26, Sigma_L 0.01\n",
      "Sigma: 0.28020569682121277, t: 27, Sigma_L 0.01\n",
      "Sigma: 0.2777598202228546, t: 28, Sigma_L 0.01\n",
      "Sigma: 0.27907249331474304, t: 29, Sigma_L 0.01\n",
      "Sigma: 0.27984774112701416, t: 30, Sigma_L 0.01\n",
      "Sigma: 0.2821264863014221, t: 31, Sigma_L 0.01\n",
      "Sigma: 0.27720484137535095, t: 32, Sigma_L 0.01\n",
      "Sigma: 0.27855509519577026, t: 33, Sigma_L 0.01\n",
      "Sigma: 0.2810351550579071, t: 34, Sigma_L 0.01\n",
      "Sigma: 0.2795107066631317, t: 35, Sigma_L 0.01\n",
      "Sigma: 0.2789420485496521, t: 36, Sigma_L 0.01\n",
      "Sigma: 0.2750330865383148, t: 37, Sigma_L 0.01\n",
      "Sigma: 0.2722947895526886, t: 38, Sigma_L 0.01\n",
      "Sigma: 0.27825066447257996, t: 39, Sigma_L 0.01\n",
      "Sigma: 0.27902650833129883, t: 40, Sigma_L 0.01\n",
      "Sigma: 0.2764780819416046, t: 41, Sigma_L 0.01\n",
      "Sigma: 0.2790413498878479, t: 42, Sigma_L 0.01\n",
      "Sigma: 0.28013166785240173, t: 43, Sigma_L 0.01\n",
      "Sigma: 0.2785833477973938, t: 44, Sigma_L 0.01\n",
      "Sigma: 0.2772955894470215, t: 45, Sigma_L 0.01\n",
      "Sigma: 0.2793450653553009, t: 46, Sigma_L 0.01\n",
      "Sigma: 0.2815641760826111, t: 47, Sigma_L 0.01\n",
      "Sigma: 0.2793654799461365, t: 48, Sigma_L 0.01\n",
      "Sigma: 0.27868664264678955, t: 49, Sigma_L 0.01\n",
      "Sigma: 0.2792718708515167, t: 50, Sigma_L 0.01\n",
      "Sigma: 0.2790026366710663, t: 51, Sigma_L 0.01\n",
      "Sigma: 0.2788461148738861, t: 52, Sigma_L 0.01\n",
      "Sigma: 0.27933675050735474, t: 53, Sigma_L 0.01\n",
      "Sigma: 0.276510626077652, t: 54, Sigma_L 0.01\n",
      "Sigma: 0.27292749285697937, t: 55, Sigma_L 0.01\n",
      "Sigma: 0.2808467447757721, t: 56, Sigma_L 0.01\n",
      "Sigma: 0.2818782925605774, t: 57, Sigma_L 0.01\n",
      "Sigma: 0.2853988707065582, t: 58, Sigma_L 0.01\n",
      "Sigma: 0.2822284996509552, t: 59, Sigma_L 0.01\n",
      "Sigma: 0.28060123324394226, t: 60, Sigma_L 0.01\n",
      "Sigma: 0.279401957988739, t: 61, Sigma_L 0.01\n",
      "Sigma: 0.27760404348373413, t: 62, Sigma_L 0.01\n",
      "Sigma: 0.28196069598197937, t: 63, Sigma_L 0.01\n",
      "Sigma: 0.28421100974082947, t: 64, Sigma_L 0.01\n",
      "Sigma: 0.27936381101608276, t: 65, Sigma_L 0.01\n",
      "Sigma: 0.28095969557762146, t: 66, Sigma_L 0.01\n",
      "Sigma: 0.2820553481578827, t: 67, Sigma_L 0.01\n",
      "Sigma: 0.281013160943985, t: 68, Sigma_L 0.01\n",
      "Sigma: 0.2772842347621918, t: 69, Sigma_L 0.01\n",
      "Sigma: 0.28308460116386414, t: 70, Sigma_L 0.01\n",
      "Sigma: 0.28339657187461853, t: 71, Sigma_L 0.01\n",
      "Sigma: 0.2752746641635895, t: 72, Sigma_L 0.01\n",
      "Sigma: 0.2744361162185669, t: 73, Sigma_L 0.01\n",
      "Sigma: 0.2805601954460144, t: 74, Sigma_L 0.01\n",
      "Sigma: 0.27416691184043884, t: 75, Sigma_L 0.01\n",
      "Sigma: 0.2794066369533539, t: 76, Sigma_L 0.01\n",
      "Sigma: 0.2775735557079315, t: 77, Sigma_L 0.01\n",
      "Sigma: 0.28050151467323303, t: 78, Sigma_L 0.01\n",
      "Sigma: 0.2832467555999756, t: 79, Sigma_L 0.01\n",
      "Sigma: 0.28156402707099915, t: 80, Sigma_L 0.01\n",
      "Sigma: 0.2846185266971588, t: 81, Sigma_L 0.01\n",
      "Sigma: 0.2815614342689514, t: 82, Sigma_L 0.01\n",
      "Sigma: 0.27713650465011597, t: 83, Sigma_L 0.01\n",
      "Sigma: 0.2807728350162506, t: 84, Sigma_L 0.01\n",
      "Sigma: 0.2811123728752136, t: 85, Sigma_L 0.01\n",
      "Sigma: 0.28594937920570374, t: 86, Sigma_L 0.01\n",
      "Sigma: 0.28162235021591187, t: 87, Sigma_L 0.01\n",
      "Sigma: 0.2830238938331604, t: 88, Sigma_L 0.01\n",
      "Sigma: 0.2788056433200836, t: 89, Sigma_L 0.01\n",
      "Sigma: 0.27887994050979614, t: 90, Sigma_L 0.01\n",
      "Sigma: 0.28009146451950073, t: 91, Sigma_L 0.01\n",
      "Sigma: 0.28088703751564026, t: 92, Sigma_L 0.01\n",
      "Sigma: 0.2801973521709442, t: 93, Sigma_L 0.01\n",
      "Sigma: 0.27730196714401245, t: 94, Sigma_L 0.01\n",
      "Sigma: 0.28036922216415405, t: 95, Sigma_L 0.01\n",
      "Sigma: 0.27791133522987366, t: 96, Sigma_L 0.01\n",
      "Sigma: 0.2760206162929535, t: 97, Sigma_L 0.01\n",
      "Sigma: 0.2770407199859619, t: 98, Sigma_L 0.01\n",
      "Sigma: 0.28175032138824463, t: 99, Sigma_L 0.01\n",
      "Sigma: 0.2832863926887512, t: 100, Sigma_L 0.01\n",
      "Sigma: 0.281162291765213, t: 101, Sigma_L 0.01\n",
      "Sigma: 0.28135091066360474, t: 102, Sigma_L 0.01\n",
      "Sigma: 0.2854551076889038, t: 103, Sigma_L 0.01\n",
      "Sigma: 0.27862170338630676, t: 104, Sigma_L 0.01\n",
      "Sigma: 0.28089097142219543, t: 105, Sigma_L 0.01\n",
      "Sigma: 0.2849377989768982, t: 106, Sigma_L 0.01\n",
      "Sigma: 0.28233519196510315, t: 107, Sigma_L 0.01\n",
      "Sigma: 0.2825152575969696, t: 108, Sigma_L 0.01\n",
      "Sigma: 0.2768094837665558, t: 109, Sigma_L 0.01\n",
      "Sigma: 0.27521082758903503, t: 110, Sigma_L 0.01\n",
      "Sigma: 0.27471083402633667, t: 111, Sigma_L 0.01\n",
      "Sigma: 0.27800920605659485, t: 112, Sigma_L 0.01\n",
      "Sigma: 0.28102928400039673, t: 113, Sigma_L 0.01\n",
      "Sigma: 0.2791011929512024, t: 114, Sigma_L 0.01\n",
      "Sigma: 0.28189727663993835, t: 115, Sigma_L 0.01\n",
      "Sigma: 0.2815740704536438, t: 116, Sigma_L 0.01\n",
      "Sigma: 0.281310498714447, t: 117, Sigma_L 0.01\n",
      "Sigma: 0.2830186188220978, t: 118, Sigma_L 0.01\n",
      "Sigma: 0.2826839089393616, t: 119, Sigma_L 0.01\n",
      "Sigma: 0.2807742655277252, t: 120, Sigma_L 0.01\n",
      "Sigma: 0.2778582274913788, t: 121, Sigma_L 0.01\n",
      "Sigma: 0.278798907995224, t: 122, Sigma_L 0.01\n",
      "Sigma: 0.2816891372203827, t: 123, Sigma_L 0.01\n",
      "Sigma: 0.27501925826072693, t: 124, Sigma_L 0.01\n",
      "Sigma: 0.27936801314353943, t: 125, Sigma_L 0.01\n",
      "Sigma: 0.2805004417896271, t: 126, Sigma_L 0.01\n",
      "Sigma: 0.27990907430648804, t: 127, Sigma_L 0.01\n",
      "Sigma: 0.28082239627838135, t: 128, Sigma_L 0.01\n",
      "Sigma: 0.280945748090744, t: 129, Sigma_L 0.01\n",
      "Sigma: 0.28171131014823914, t: 130, Sigma_L 0.01\n",
      "Sigma: 0.2775934338569641, t: 131, Sigma_L 0.01\n",
      "Sigma: 0.28373783826828003, t: 132, Sigma_L 0.01\n",
      "Sigma: 0.27887168526649475, t: 133, Sigma_L 0.01\n",
      "Sigma: 0.28091123700141907, t: 134, Sigma_L 0.01\n",
      "Sigma: 0.28177836537361145, t: 135, Sigma_L 0.01\n",
      "Sigma: 0.27653104066848755, t: 136, Sigma_L 0.01\n",
      "Sigma: 0.27744969725608826, t: 137, Sigma_L 0.01\n",
      "Sigma: 0.27811741828918457, t: 138, Sigma_L 0.01\n",
      "Sigma: 0.2782059609889984, t: 139, Sigma_L 0.01\n",
      "Sigma: 0.28234097361564636, t: 140, Sigma_L 0.01\n",
      "Sigma: 0.27729371190071106, t: 141, Sigma_L 0.01\n",
      "Sigma: 0.2777846157550812, t: 142, Sigma_L 0.01\n",
      "Sigma: 0.280355304479599, t: 143, Sigma_L 0.01\n",
      "Sigma: 0.28091201186180115, t: 144, Sigma_L 0.01\n",
      "Sigma: 0.28039610385894775, t: 145, Sigma_L 0.01\n",
      "Sigma: 0.27767014503479004, t: 146, Sigma_L 0.01\n",
      "Sigma: 0.2755788564682007, t: 147, Sigma_L 0.01\n",
      "Sigma: 0.27907222509384155, t: 148, Sigma_L 0.01\n",
      "Sigma: 0.277462363243103, t: 149, Sigma_L 0.01\n",
      "Sigma: 0.27822691202163696, t: 150, Sigma_L 0.01\n",
      "Sigma: 0.27643707394599915, t: 151, Sigma_L 0.01\n",
      "Sigma: 0.2811453640460968, t: 152, Sigma_L 0.01\n",
      "Sigma: 0.27898067235946655, t: 153, Sigma_L 0.01\n",
      "Sigma: 0.2787781059741974, t: 154, Sigma_L 0.01\n",
      "Sigma: 0.27865689992904663, t: 155, Sigma_L 0.01\n",
      "Sigma: 0.27824777364730835, t: 156, Sigma_L 0.01\n",
      "Sigma: 0.2788110673427582, t: 157, Sigma_L 0.01\n",
      "Sigma: 0.2786719799041748, t: 158, Sigma_L 0.01\n",
      "Sigma: 0.28014126420021057, t: 159, Sigma_L 0.01\n",
      "Sigma: 0.2776499390602112, t: 160, Sigma_L 0.01\n",
      "Sigma: 0.2807365655899048, t: 161, Sigma_L 0.01\n",
      "Sigma: 0.28142091631889343, t: 162, Sigma_L 0.01\n",
      "Sigma: 0.28294363617897034, t: 163, Sigma_L 0.01\n",
      "Sigma: 0.2811615765094757, t: 164, Sigma_L 0.01\n",
      "Sigma: 0.282095342874527, t: 165, Sigma_L 0.01\n",
      "Sigma: 0.2772044539451599, t: 166, Sigma_L 0.01\n",
      "Sigma: 0.27993205189704895, t: 167, Sigma_L 0.01\n",
      "Sigma: 0.27698734402656555, t: 168, Sigma_L 0.01\n",
      "Sigma: 0.2810044586658478, t: 169, Sigma_L 0.01\n",
      "Sigma: 0.28102758526802063, t: 170, Sigma_L 0.01\n",
      "Sigma: 0.2837431728839874, t: 171, Sigma_L 0.01\n",
      "Sigma: 0.2802102863788605, t: 172, Sigma_L 0.01\n",
      "Sigma: 0.28039172291755676, t: 173, Sigma_L 0.01\n",
      "Sigma: 0.2842812240123749, t: 174, Sigma_L 0.01\n",
      "Sigma: 0.2800959646701813, t: 175, Sigma_L 0.01\n",
      "Sigma: 0.27466920018196106, t: 176, Sigma_L 0.01\n",
      "Sigma: 0.27445188164711, t: 177, Sigma_L 0.01\n",
      "Sigma: 0.27829983830451965, t: 178, Sigma_L 0.01\n",
      "Sigma: 0.2800855338573456, t: 179, Sigma_L 0.01\n",
      "Sigma: 0.28227752447128296, t: 180, Sigma_L 0.01\n",
      "Sigma: 0.2779448926448822, t: 181, Sigma_L 0.01\n",
      "Sigma: 0.27742528915405273, t: 182, Sigma_L 0.01\n",
      "Sigma: 0.27210870385169983, t: 183, Sigma_L 0.01\n",
      "Sigma: 0.2715085446834564, t: 184, Sigma_L 0.01\n",
      "Sigma: 0.2753758430480957, t: 185, Sigma_L 0.01\n",
      "Sigma: 0.279866486787796, t: 186, Sigma_L 0.01\n",
      "Sigma: 0.27695950865745544, t: 187, Sigma_L 0.01\n",
      "Sigma: 0.2769649624824524, t: 188, Sigma_L 0.01\n",
      "Sigma: 0.27521026134490967, t: 189, Sigma_L 0.01\n",
      "Sigma: 0.2758552134037018, t: 190, Sigma_L 0.01\n",
      "Sigma: 0.27224811911582947, t: 191, Sigma_L 0.01\n",
      "Sigma: 0.2735438942909241, t: 192, Sigma_L 0.01\n",
      "Sigma: 0.27308231592178345, t: 193, Sigma_L 0.01\n",
      "Sigma: 0.27347657084465027, t: 194, Sigma_L 0.01\n",
      "Sigma: 0.2765258550643921, t: 195, Sigma_L 0.01\n",
      "Sigma: 0.2762302756309509, t: 196, Sigma_L 0.01\n",
      "Sigma: 0.27664658427238464, t: 197, Sigma_L 0.01\n",
      "Sigma: 0.2738455533981323, t: 198, Sigma_L 0.01\n",
      "Sigma: 0.27937060594558716, t: 199, Sigma_L 0.01\n",
      "Sigma: 0.28203293681144714, t: 200, Sigma_L 0.01\n",
      "Sigma: 0.2827591001987457, t: 201, Sigma_L 0.01\n",
      "Sigma: 0.280556321144104, t: 202, Sigma_L 0.01\n",
      "Sigma: 0.27580884099006653, t: 203, Sigma_L 0.01\n",
      "Sigma: 0.27640166878700256, t: 204, Sigma_L 0.01\n",
      "Sigma: 0.27937471866607666, t: 205, Sigma_L 0.01\n",
      "Sigma: 0.2801986038684845, t: 206, Sigma_L 0.01\n",
      "Sigma: 0.2779622972011566, t: 207, Sigma_L 0.01\n",
      "Sigma: 0.2815416157245636, t: 208, Sigma_L 0.01\n",
      "Sigma: 0.28064095973968506, t: 209, Sigma_L 0.01\n",
      "Sigma: 0.28020647168159485, t: 210, Sigma_L 0.01\n",
      "Sigma: 0.2787424921989441, t: 211, Sigma_L 0.01\n",
      "Sigma: 0.28100553154945374, t: 212, Sigma_L 0.01\n",
      "Sigma: 0.2811841666698456, t: 213, Sigma_L 0.01\n",
      "Sigma: 0.2812250852584839, t: 214, Sigma_L 0.01\n",
      "Sigma: 0.28033843636512756, t: 215, Sigma_L 0.01\n",
      "Sigma: 0.2784847915172577, t: 216, Sigma_L 0.01\n",
      "Sigma: 0.27887651324272156, t: 217, Sigma_L 0.01\n",
      "Sigma: 0.27780789136886597, t: 218, Sigma_L 0.01\n",
      "Sigma: 0.27938148379325867, t: 219, Sigma_L 0.01\n",
      "Sigma: 0.2820209562778473, t: 220, Sigma_L 0.01\n",
      "Sigma: 0.2797469198703766, t: 221, Sigma_L 0.01\n",
      "Sigma: 0.28217169642448425, t: 222, Sigma_L 0.01\n",
      "Sigma: 0.2760717272758484, t: 223, Sigma_L 0.01\n",
      "Sigma: 0.27526620030403137, t: 224, Sigma_L 0.01\n",
      "Sigma: 0.2757471203804016, t: 225, Sigma_L 0.01\n",
      "Sigma: 0.2797953486442566, t: 226, Sigma_L 0.01\n",
      "Sigma: 0.27875688672065735, t: 227, Sigma_L 0.01\n",
      "Sigma: 0.280764102935791, t: 228, Sigma_L 0.01\n",
      "Sigma: 0.28164124488830566, t: 229, Sigma_L 0.01\n",
      "Sigma: 0.2784960865974426, t: 230, Sigma_L 0.01\n",
      "Sigma: 0.28099504113197327, t: 231, Sigma_L 0.01\n",
      "Sigma: 0.2811494469642639, t: 232, Sigma_L 0.01\n",
      "Sigma: 0.2814532518386841, t: 233, Sigma_L 0.01\n",
      "Sigma: 0.2774498164653778, t: 234, Sigma_L 0.01\n",
      "Sigma: 0.2807585895061493, t: 235, Sigma_L 0.01\n",
      "Sigma: 0.28002697229385376, t: 236, Sigma_L 0.01\n",
      "Sigma: 0.2802788317203522, t: 237, Sigma_L 0.01\n",
      "Sigma: 0.2785549461841583, t: 238, Sigma_L 0.01\n",
      "Sigma: 0.28165820240974426, t: 239, Sigma_L 0.01\n",
      "Sigma: 0.2760802209377289, t: 240, Sigma_L 0.01\n",
      "Sigma: 0.28138118982315063, t: 241, Sigma_L 0.01\n",
      "Sigma: 0.27267077565193176, t: 242, Sigma_L 0.01\n",
      "Sigma: 0.26587602496147156, t: 243, Sigma_L 0.01\n",
      "Sigma: 0.26593074202537537, t: 244, Sigma_L 0.01\n",
      "Sigma: 0.2685602903366089, t: 245, Sigma_L 0.01\n",
      "Sigma: 0.27524593472480774, t: 246, Sigma_L 0.01\n",
      "Sigma: 0.2697179913520813, t: 247, Sigma_L 0.01\n",
      "Sigma: 0.27330777049064636, t: 248, Sigma_L 0.01\n",
      "Sigma: 0.2743162512779236, t: 249, Sigma_L 0.01\n",
      "Sigma: 0.2773241102695465, t: 250, Sigma_L 0.01\n",
      "Sigma: 0.27641773223876953, t: 251, Sigma_L 0.01\n",
      "Sigma: 0.2779684364795685, t: 252, Sigma_L 0.01\n",
      "Sigma: 0.27934959530830383, t: 253, Sigma_L 0.01\n",
      "Sigma: 0.27303463220596313, t: 254, Sigma_L 0.01\n",
      "Sigma: 0.27533477544784546, t: 255, Sigma_L 0.01\n",
      "Sigma: 0.2770099639892578, t: 256, Sigma_L 0.01\n",
      "Sigma: 0.2779254615306854, t: 257, Sigma_L 0.01\n",
      "Sigma: 0.2775050103664398, t: 258, Sigma_L 0.01\n",
      "Sigma: 0.2786905765533447, t: 259, Sigma_L 0.01\n",
      "Sigma: 0.27627596259117126, t: 260, Sigma_L 0.01\n",
      "Sigma: 0.27766039967536926, t: 261, Sigma_L 0.01\n",
      "Sigma: 0.26799091696739197, t: 262, Sigma_L 0.01\n",
      "Sigma: 0.2749834358692169, t: 263, Sigma_L 0.01\n",
      "Sigma: 0.2762431502342224, t: 264, Sigma_L 0.01\n",
      "Sigma: 0.2768767178058624, t: 265, Sigma_L 0.01\n",
      "Sigma: 0.26818200945854187, t: 266, Sigma_L 0.01\n",
      "Sigma: 0.26879698038101196, t: 267, Sigma_L 0.01\n",
      "Sigma: 0.27016451954841614, t: 268, Sigma_L 0.01\n",
      "Sigma: 0.2645341753959656, t: 269, Sigma_L 0.01\n",
      "Sigma: 0.2623738944530487, t: 270, Sigma_L 0.01\n",
      "Sigma: 0.2596398591995239, t: 271, Sigma_L 0.01\n",
      "Sigma: 0.26280471682548523, t: 272, Sigma_L 0.01\n",
      "Sigma: 0.26548078656196594, t: 273, Sigma_L 0.01\n",
      "Sigma: 0.26125600934028625, t: 274, Sigma_L 0.01\n",
      "Sigma: 0.26753953099250793, t: 275, Sigma_L 0.01\n",
      "Sigma: 0.2739081084728241, t: 276, Sigma_L 0.01\n",
      "Sigma: 0.2713879644870758, t: 277, Sigma_L 0.01\n",
      "Sigma: 0.2718042731285095, t: 278, Sigma_L 0.01\n",
      "Sigma: 0.2693071961402893, t: 279, Sigma_L 0.01\n",
      "Sigma: 0.2628015875816345, t: 280, Sigma_L 0.01\n",
      "Sigma: 0.2584887444972992, t: 281, Sigma_L 0.01\n",
      "Sigma: 0.25987187027931213, t: 282, Sigma_L 0.01\n",
      "Sigma: 0.26199236512184143, t: 283, Sigma_L 0.01\n",
      "Sigma: 0.2632986903190613, t: 284, Sigma_L 0.01\n",
      "Sigma: 0.2635667324066162, t: 285, Sigma_L 0.01\n",
      "Sigma: 0.26608043909072876, t: 286, Sigma_L 0.01\n",
      "Sigma: 0.2668035626411438, t: 287, Sigma_L 0.01\n",
      "Sigma: 0.2653059661388397, t: 288, Sigma_L 0.01\n",
      "Sigma: 0.26589471101760864, t: 289, Sigma_L 0.01\n",
      "Sigma: 0.26578181982040405, t: 290, Sigma_L 0.01\n",
      "Sigma: 0.26589855551719666, t: 291, Sigma_L 0.01\n",
      "Sigma: 0.26133227348327637, t: 292, Sigma_L 0.01\n",
      "Sigma: 0.2610625624656677, t: 293, Sigma_L 0.01\n",
      "Sigma: 0.26450082659721375, t: 294, Sigma_L 0.01\n",
      "Sigma: 0.2617488205432892, t: 295, Sigma_L 0.01\n",
      "Sigma: 0.2675548493862152, t: 296, Sigma_L 0.01\n",
      "Sigma: 0.26933592557907104, t: 297, Sigma_L 0.01\n",
      "Sigma: 0.2670573592185974, t: 298, Sigma_L 0.01\n",
      "Sigma: 0.2662182152271271, t: 299, Sigma_L 0.01\n",
      "Sigma: 0.2658444344997406, t: 300, Sigma_L 0.01\n",
      "Sigma: 0.2594465911388397, t: 301, Sigma_L 0.01\n",
      "Sigma: 0.26255735754966736, t: 302, Sigma_L 0.01\n",
      "Sigma: 0.2637127935886383, t: 303, Sigma_L 0.01\n",
      "Sigma: 0.26378992199897766, t: 304, Sigma_L 0.01\n",
      "Sigma: 0.25858864188194275, t: 305, Sigma_L 0.01\n",
      "Sigma: 0.2625451385974884, t: 306, Sigma_L 0.01\n",
      "Sigma: 0.2513968348503113, t: 307, Sigma_L 0.01\n",
      "Sigma: 0.26288464665412903, t: 308, Sigma_L 0.01\n",
      "Sigma: 0.2626934349536896, t: 309, Sigma_L 0.01\n",
      "Sigma: 0.26062628626823425, t: 310, Sigma_L 0.01\n",
      "Sigma: 0.2655525505542755, t: 311, Sigma_L 0.01\n",
      "Sigma: 0.25493597984313965, t: 312, Sigma_L 0.01\n",
      "Sigma: 0.2620733082294464, t: 313, Sigma_L 0.01\n",
      "Sigma: 0.2627386450767517, t: 314, Sigma_L 0.01\n",
      "Sigma: 0.2665063142776489, t: 315, Sigma_L 0.01\n",
      "Sigma: 0.2629461884498596, t: 316, Sigma_L 0.01\n",
      "Sigma: 0.26183003187179565, t: 317, Sigma_L 0.01\n",
      "Sigma: 0.2596682012081146, t: 318, Sigma_L 0.01\n",
      "Sigma: 0.2602379322052002, t: 319, Sigma_L 0.01\n",
      "Sigma: 0.25789907574653625, t: 320, Sigma_L 0.01\n",
      "Sigma: 0.25722309947013855, t: 321, Sigma_L 0.01\n",
      "Sigma: 0.258356511592865, t: 322, Sigma_L 0.01\n",
      "Sigma: 0.25731149315834045, t: 323, Sigma_L 0.01\n",
      "Sigma: 0.25602608919143677, t: 324, Sigma_L 0.01\n",
      "Sigma: 0.2581923305988312, t: 325, Sigma_L 0.01\n",
      "Sigma: 0.2612287700176239, t: 326, Sigma_L 0.01\n",
      "Sigma: 0.26063188910484314, t: 327, Sigma_L 0.01\n",
      "Sigma: 0.26424023509025574, t: 328, Sigma_L 0.01\n",
      "Sigma: 0.2616924047470093, t: 329, Sigma_L 0.01\n",
      "Sigma: 0.26609399914741516, t: 330, Sigma_L 0.01\n",
      "Sigma: 0.2607620358467102, t: 331, Sigma_L 0.01\n",
      "Sigma: 0.2593425214290619, t: 332, Sigma_L 0.01\n",
      "Sigma: 0.24878238141536713, t: 333, Sigma_L 0.01\n",
      "Sigma: 0.25507086515426636, t: 334, Sigma_L 0.01\n",
      "Sigma: 0.24968577921390533, t: 335, Sigma_L 0.01\n",
      "Sigma: 0.24499668180942535, t: 336, Sigma_L 0.01\n",
      "Sigma: 0.2404005378484726, t: 337, Sigma_L 0.01\n",
      "Sigma: 0.2448800504207611, t: 338, Sigma_L 0.01\n",
      "Sigma: 0.23933155834674835, t: 339, Sigma_L 0.01\n",
      "Sigma: 0.23848918080329895, t: 340, Sigma_L 0.01\n",
      "Sigma: 0.2345941960811615, t: 341, Sigma_L 0.01\n",
      "Sigma: 0.23866866528987885, t: 342, Sigma_L 0.01\n",
      "Sigma: 0.23610128462314606, t: 343, Sigma_L 0.01\n",
      "Sigma: 0.23666724562644958, t: 344, Sigma_L 0.01\n",
      "Sigma: 0.23573394119739532, t: 345, Sigma_L 0.01\n",
      "Sigma: 0.23072709143161774, t: 346, Sigma_L 0.01\n",
      "Sigma: 0.23086906969547272, t: 347, Sigma_L 0.01\n",
      "Sigma: 0.23095856606960297, t: 348, Sigma_L 0.01\n",
      "Sigma: 0.23126967251300812, t: 349, Sigma_L 0.01\n",
      "Sigma: 0.23977720737457275, t: 350, Sigma_L 0.01\n",
      "Sigma: 0.22970931231975555, t: 351, Sigma_L 0.01\n",
      "Sigma: 0.22876398265361786, t: 352, Sigma_L 0.01\n",
      "Sigma: 0.23224091529846191, t: 353, Sigma_L 0.01\n",
      "Sigma: 0.22847913205623627, t: 354, Sigma_L 0.01\n",
      "Sigma: 0.23018884658813477, t: 355, Sigma_L 0.01\n",
      "Sigma: 0.22584021091461182, t: 356, Sigma_L 0.01\n",
      "Sigma: 0.2256130427122116, t: 357, Sigma_L 0.01\n",
      "Sigma: 0.22584593296051025, t: 358, Sigma_L 0.01\n",
      "Sigma: 0.2214924544095993, t: 359, Sigma_L 0.01\n",
      "Sigma: 0.22056284546852112, t: 360, Sigma_L 0.01\n",
      "Sigma: 0.22103221714496613, t: 361, Sigma_L 0.01\n",
      "Sigma: 0.21733097732067108, t: 362, Sigma_L 0.01\n",
      "Sigma: 0.21470491588115692, t: 363, Sigma_L 0.01\n",
      "Sigma: 0.2145475149154663, t: 364, Sigma_L 0.01\n",
      "Sigma: 0.21355651319026947, t: 365, Sigma_L 0.01\n",
      "Sigma: 0.21345452964305878, t: 366, Sigma_L 0.01\n",
      "Sigma: 0.21679635345935822, t: 367, Sigma_L 0.01\n",
      "Sigma: 0.21320569515228271, t: 368, Sigma_L 0.01\n",
      "Sigma: 0.21281437575817108, t: 369, Sigma_L 0.01\n",
      "Sigma: 0.21615317463874817, t: 370, Sigma_L 0.01\n",
      "Sigma: 0.2108064442873001, t: 371, Sigma_L 0.01\n",
      "Sigma: 0.20354902744293213, t: 372, Sigma_L 0.01\n",
      "Sigma: 0.2056543081998825, t: 373, Sigma_L 0.01\n",
      "Sigma: 0.20393648743629456, t: 374, Sigma_L 0.01\n",
      "Sigma: 0.20002435147762299, t: 375, Sigma_L 0.01\n",
      "Sigma: 0.19402863085269928, t: 376, Sigma_L 0.01\n",
      "Sigma: 0.19256548583507538, t: 377, Sigma_L 0.01\n",
      "Sigma: 0.1913093775510788, t: 378, Sigma_L 0.01\n",
      "Sigma: 0.19228744506835938, t: 379, Sigma_L 0.01\n",
      "Sigma: 0.18913866579532623, t: 380, Sigma_L 0.01\n",
      "Sigma: 0.1899350881576538, t: 381, Sigma_L 0.01\n",
      "Sigma: 0.19338615238666534, t: 382, Sigma_L 0.01\n",
      "Sigma: 0.1881883442401886, t: 383, Sigma_L 0.01\n",
      "Sigma: 0.17988340556621552, t: 384, Sigma_L 0.01\n",
      "Sigma: 0.18000786006450653, t: 385, Sigma_L 0.01\n",
      "Sigma: 0.17834816873073578, t: 386, Sigma_L 0.01\n",
      "Sigma: 0.1771572381258011, t: 387, Sigma_L 0.01\n",
      "Sigma: 0.1842099279165268, t: 388, Sigma_L 0.01\n",
      "Sigma: 0.1770526021718979, t: 389, Sigma_L 0.01\n",
      "Sigma: 0.1788763701915741, t: 390, Sigma_L 0.01\n",
      "Sigma: 0.17157264053821564, t: 391, Sigma_L 0.01\n",
      "Sigma: 0.1681825816631317, t: 392, Sigma_L 0.01\n",
      "Sigma: 0.16321797668933868, t: 393, Sigma_L 0.01\n",
      "Sigma: 0.1601206511259079, t: 394, Sigma_L 0.01\n",
      "Sigma: 0.15526345372200012, t: 395, Sigma_L 0.01\n",
      "Sigma: 0.15504471957683563, t: 396, Sigma_L 0.01\n",
      "Sigma: 0.1547297090291977, t: 397, Sigma_L 0.01\n",
      "Sigma: 0.154144287109375, t: 398, Sigma_L 0.01\n",
      "Sigma: 0.14756262302398682, t: 399, Sigma_L 0.01\n",
      "Sigma: 0.14705373346805573, t: 400, Sigma_L 0.01\n",
      "Sigma: 0.13946029543876648, t: 401, Sigma_L 0.01\n",
      "Sigma: 0.14338281750679016, t: 402, Sigma_L 0.01\n",
      "Sigma: 0.1394055336713791, t: 403, Sigma_L 0.01\n",
      "Sigma: 0.13303808867931366, t: 404, Sigma_L 0.01\n",
      "Sigma: 0.13103656470775604, t: 405, Sigma_L 0.01\n",
      "Sigma: 0.1224786713719368, t: 406, Sigma_L 0.01\n",
      "Sigma: 0.12059871107339859, t: 407, Sigma_L 0.01\n",
      "Sigma: 0.10728345066308975, t: 408, Sigma_L 0.01\n",
      "Sigma: 0.10261301696300507, t: 409, Sigma_L 0.01\n",
      "Sigma: 0.09837261587381363, t: 410, Sigma_L 0.01\n",
      "Sigma: 0.09453359991312027, t: 411, Sigma_L 0.01\n",
      "Sigma: 0.09168893843889236, t: 412, Sigma_L 0.01\n",
      "Sigma: 0.08771835267543793, t: 413, Sigma_L 0.01\n",
      "Sigma: 0.08464358001947403, t: 414, Sigma_L 0.01\n",
      "Sigma: 0.07508789747953415, t: 415, Sigma_L 0.01\n",
      "Sigma: 0.07264064252376556, t: 416, Sigma_L 0.01\n",
      "Sigma: 0.06761954724788666, t: 417, Sigma_L 0.01\n",
      "Sigma: 0.06528551131486893, t: 418, Sigma_L 0.01\n",
      "Sigma: 0.06352655589580536, t: 419, Sigma_L 0.01\n",
      "Sigma: 0.06294181197881699, t: 420, Sigma_L 0.01\n",
      "Sigma: 0.06037871167063713, t: 421, Sigma_L 0.01\n",
      "Sigma: 0.059203941375017166, t: 422, Sigma_L 0.01\n",
      "Sigma: 0.05810755118727684, t: 423, Sigma_L 0.01\n",
      "Sigma: 0.05560653284192085, t: 424, Sigma_L 0.01\n",
      "Sigma: 0.052362751215696335, t: 425, Sigma_L 0.01\n",
      "Sigma: 0.05080672726035118, t: 426, Sigma_L 0.01\n",
      "Sigma: 0.04825468733906746, t: 427, Sigma_L 0.01\n",
      "Sigma: 0.04578780382871628, t: 428, Sigma_L 0.01\n",
      "Sigma: 0.0436762236058712, t: 429, Sigma_L 0.01\n",
      "Sigma: 0.041861288249492645, t: 430, Sigma_L 0.01\n",
      "Sigma: 0.04081401228904724, t: 431, Sigma_L 0.01\n",
      "Sigma: 0.03814613074064255, t: 432, Sigma_L 0.01\n",
      "Sigma: 0.037904493510723114, t: 433, Sigma_L 0.01\n",
      "Sigma: 0.037163104861974716, t: 434, Sigma_L 0.01\n",
      "Sigma: 0.03533753380179405, t: 435, Sigma_L 0.01\n",
      "Sigma: 0.03504008427262306, t: 436, Sigma_L 0.01\n",
      "Sigma: 0.034712519496679306, t: 437, Sigma_L 0.01\n",
      "Sigma: 0.03391777351498604, t: 438, Sigma_L 0.01\n",
      "Sigma: 0.033065106719732285, t: 439, Sigma_L 0.01\n",
      "Sigma: 0.03258931264281273, t: 440, Sigma_L 0.01\n",
      "Sigma: 0.03122659958899021, t: 441, Sigma_L 0.01\n",
      "Sigma: 0.03002449870109558, t: 442, Sigma_L 0.01\n",
      "Sigma: 0.029524680227041245, t: 443, Sigma_L 0.01\n",
      "Sigma: 0.028185028582811356, t: 444, Sigma_L 0.01\n",
      "Sigma: 0.02736622653901577, t: 445, Sigma_L 0.01\n",
      "Sigma: 0.026244040578603745, t: 446, Sigma_L 0.01\n",
      "Sigma: 0.025545552372932434, t: 447, Sigma_L 0.01\n",
      "Sigma: 0.024625156074762344, t: 448, Sigma_L 0.01\n",
      "Sigma: 0.02390752173960209, t: 449, Sigma_L 0.01\n",
      "Sigma: 0.02286912128329277, t: 450, Sigma_L 0.01\n",
      "Sigma: 0.022225109860301018, t: 451, Sigma_L 0.01\n",
      "Sigma: 0.021861393004655838, t: 452, Sigma_L 0.01\n",
      "Sigma: 0.02084888145327568, t: 453, Sigma_L 0.01\n",
      "Sigma: 0.02031262405216694, t: 454, Sigma_L 0.01\n",
      "Sigma: 0.019775377586483955, t: 455, Sigma_L 0.01\n",
      "Sigma: 0.018928494304418564, t: 456, Sigma_L 0.01\n",
      "Sigma: 0.0184007678180933, t: 457, Sigma_L 0.01\n",
      "Sigma: 0.017768627032637596, t: 458, Sigma_L 0.01\n",
      "Sigma: 0.017084186896681786, t: 459, Sigma_L 0.01\n",
      "Sigma: 0.016567852348089218, t: 460, Sigma_L 0.01\n",
      "Sigma: 0.01584499701857567, t: 461, Sigma_L 0.01\n",
      "Sigma: 0.015243304893374443, t: 462, Sigma_L 0.01\n",
      "Sigma: 0.014817922376096249, t: 463, Sigma_L 0.01\n",
      "Sigma: 0.014259188435971737, t: 464, Sigma_L 0.01\n",
      "Sigma: 0.013738068751990795, t: 465, Sigma_L 0.01\n",
      "Sigma: 0.013350868597626686, t: 466, Sigma_L 0.01\n",
      "Sigma: 0.012805378995835781, t: 467, Sigma_L 0.01\n",
      "Sigma: 0.012401499785482883, t: 468, Sigma_L 0.01\n",
      "Sigma: 0.011889440007507801, t: 469, Sigma_L 0.01\n",
      "Sigma: 0.01140893716365099, t: 470, Sigma_L 0.01\n",
      "Sigma: 0.010967162437736988, t: 471, Sigma_L 0.01\n",
      "Sigma: 0.010672494769096375, t: 472, Sigma_L 0.01\n",
      "Sigma: 0.010445626452565193, t: 473, Sigma_L 0.01\n",
      "Sigma: 0.010020708665251732, t: 474, Sigma_L 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def universal_inverse_solver(M, M_T, x_c, denoiser, sigma_0=1, sigma_L=0.01, h_0=0.01, beta=0.01):\n",
    "\n",
    "\n",
    "\n",
    "# For synthesis, both M and M_T are zero like or shape sample image\n",
    "# Images are mnist, so 28x28\n",
    "# Create a Tensor of zeros with the same shape as the sample image\n",
    "\n",
    "# Input image is 28x28 of zeros and noise will be added to it\n",
    "# This will be synthesized by the denoiser\n",
    "patch_size = (1, 28, 28) # 1 channel, 28x28\n",
    "x_c = torch.zeros(patch_size) \n",
    "\n",
    "synth = universal_inverse_solver(x_c, denoiser)\n",
    "\n",
    "# Reshape the synthesized image to be 28x28\n",
    "synth = synth.view(1,1,28,28)\n",
    "\n",
    "# Show synthesized image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(synth[0,0,:,:].detach().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
